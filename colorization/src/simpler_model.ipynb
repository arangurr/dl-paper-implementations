{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simpler_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7Agqbsok67VJ","colab_type":"text"},"cell_type":"markdown","source":["# Image Colorization using CNNs\n","\n","In this notebook we explore how to produce a plausible colorized image from a grayscale image."]},{"metadata":{"id":"tANVOAg47lWZ","colab_type":"text"},"cell_type":"markdown","source":["## Setup"]},{"metadata":{"id":"nEpD1Q-n7TG6","colab_type":"text"},"cell_type":"markdown","source":["We are going to use Google Drive's storage to save and load data. First, we need to authenticate our user.\n","We assume everything will be inside a folder named 'shared' in the root of Drive. This cell can be skipped, but then the model won't be saved later using our method."]},{"metadata":{"id":"rG06ooKy2ud7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"outputId":"ebb7d6e3-a654-46d6-f894-2863b68a1c04","executionInfo":{"status":"ok","timestamp":1542690974310,"user_tz":360,"elapsed":25839,"user":{"displayName":"Jaime Cernuda Garcia","photoUrl":"","userId":"05776885657832907950"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"metadata":{"id":"9u-aqSSt7s8W","colab_type":"text"},"cell_type":"markdown","source":["Other imports that will be used throughout the code:"]},{"metadata":{"id":"_NaAqSsKKD0C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"cc387943-63b0-44ee-ab2c-3b52c67a5a99","executionInfo":{"status":"ok","timestamp":1542690975387,"user_tz":360,"elapsed":4796,"user":{"displayName":"Jaime Cernuda Garcia","photoUrl":"","userId":"05776885657832907950"}}},"cell_type":"code","source":["from keras.datasets import cifar10\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage import img_as_ubyte\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.transform import resize\n","import os\n","import keras\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Conv2D, BatchNormalization, UpSampling2D, ZeroPadding2D, Conv2DTranspose, Lambda, Softmax, Add, Input, Activation\n","from keras.preprocessing.image import ImageDataGenerator\n","import multiprocessing"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"SZZK4ZSdfjj2","colab_type":"text"},"cell_type":"markdown","source":["## Model definition\n","\n","First we define the model hyperparameters as follows:\n"]},{"metadata":{"id":"rTiacA5R8oD8","colab_type":"code","colab":{}},"cell_type":"code","source":["h, w = (32, 32)\n","input_shape = (h,w,1) # Channels last\n","batch_size = 16\n","epochs = 5\n","nb_classes = 313"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KgS4TZmEB4Rb","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.callbacks import TensorBoard\n","\n","model = Sequential()\n","\n","model.add(Conv2D(64, kernel_size=3, padding='same', strides=1, activation='relu', input_shape=input_shape))\n","model.add(Conv2D(64, kernel_size=3, padding='same', strides=2, activation='relu'))\n","model.add(Conv2D(128, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(128, kernel_size=3, padding='same' ,strides=2, activation='relu'))\n","model.add(Conv2D(256, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(256, kernel_size=3, padding='same', strides=2, activation='relu'))\n","model.add(Conv2D(512, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(256, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(128, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(64, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(32, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(16, kernel_size=3, padding='same', strides=1, activation='relu'))\n","model.add(Conv2D(2, kernel_size=3, padding='same', strides=1, activation='tanh'))\n","model.add(UpSampling2D((2, 2)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DDubxGaDQqAT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":669},"outputId":"4676fd6c-9e19-4903-e13e-a6049ce2c53b","executionInfo":{"status":"ok","timestamp":1542690975653,"user_tz":360,"elapsed":1037,"user":{"displayName":"Jaime Cernuda Garcia","photoUrl":"","userId":"05776885657832907950"}}},"cell_type":"code","source":["model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 4, 4, 256)         590080    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 4, 4, 256)         1179904   \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 4, 4, 128)         295040    \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 8, 8, 64)          73792     \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 16, 16, 32)        18464     \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 16, 16, 16)        4624      \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 16, 16, 2)         290       \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 32, 32, 2)         0         \n","=================================================================\n","Total params: 3,896,530\n","Trainable params: 3,896,530\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"kATyD0e__a55","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='mse', optimizer='adam')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"geKrJRN89AK2","colab_type":"text"},"cell_type":"markdown","source":["## Model training\n","\n","Before actually training the model, we have to specify how we are going to feed the data. We will use a Generator derived from the Sequence class so we can use multiprocessing"]},{"metadata":{"id":"T5PUatCm5fnT","colab_type":"code","colab":{}},"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","  \n","  def __init__(self, data, batch_size=16, dim=(32,32), shuffle=True):\n","    'Initialization'\n","    self.dim = dim\n","    self.data = data\n","    self.batch_size = batch_size\n","    self.shuffle = shuffle\n","    self.on_epoch_end()\n","    print(\"generator initialzed with \", len(data), \"samples\")\n","    \n","  def on_epoch_end(self):\n","    self.indexes = np.arange(len(self.data))\n","    if self.shuffle == True:\n","      np.random.shuffle(self.indexes)\n","      \n","  def __data_generation(self, idx_temp):\n","    \n","    X = np.empty((self.batch_size, *self.dim, 1)) # 1 Channel\n","#     y = np.empty((self.batch_size, *self.dim, 314)) # 313+1 channels\n","    y = np.empty((self.batch_size, *self.dim, 2)) # a,b channels\n","    \n","    for i, idx in enumerate(idx_temp):\n","      lab = np.asarray(rgb2lab(resize(self.data[idx], self.dim)/255.0))\n","      \n","      X[i,] = lab[:,:,:1]/100.\n","      y[i,] = (lab[:,:,1:3]/128.).reshape((*self.dim, 2))\n","#       y[i,] = transformY(lab[:,:,1:3], nearest, prior_factor, nb_q)\n","    \n","    return X, y\n","  \n","  def __len__(self):\n","    'Denotes the number of batches per epoch'\n","    return int(np.floor(len(self.data) / self.batch_size))\n","  \n","  def __getitem__(self, index):\n","    'Generate one batch of data'\n","    # Generate indexes of the batch\n","    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","    # Find list of IDs\n","    list_IDs_temp = [self.indexes[k] for k in indexes]\n","\n","    # Generate data\n","    X, y = self.__data_generation(list_IDs_temp)\n","\n","    return X, y\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_q2OQSb_9h-X","colab_type":"text"},"cell_type":"markdown","source":["Actual training using the CIFAR10 dataset using a train and validation set."]},{"metadata":{"id":"tQ8u6QszERgf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":321},"outputId":"866568fd-ba28-4116-c510-a5914fa19c8e","executionInfo":{"status":"ok","timestamp":1542692010563,"user_tz":360,"elapsed":1030328,"user":{"displayName":"Jaime Cernuda Garcia","photoUrl":"","userId":"05776885657832907950"}}},"cell_type":"code","source":["(raw_train, _), (raw_test, _) = cifar10.load_data()\n","\n","training_generator = DataGenerator(data=raw_train, batch_size=batch_size, shuffle=True, dim=(h,w))\n","testing_generator = DataGenerator(data=raw_test,  batch_size=batch_size, shuffle=False, dim=(h,w))\n","\n","model.fit_generator(training_generator,\n","                    workers=multiprocessing.cpu_count(),\n","                    validation_data=testing_generator,\n","                    epochs=epochs,\n","                    verbose=1)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 17s 0us/step\n","generator initialzed with  50000 samples\n","generator initialzed with  10000 samples\n","Epoch 1/5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n","  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"],"name":"stderr"},{"output_type":"stream","text":["3125/3125 [==============================] - 207s 66ms/step - loss: 1.0494e-07 - val_loss: 9.2206e-08\n","Epoch 2/5\n","3125/3125 [==============================] - 203s 65ms/step - loss: 9.7318e-08 - val_loss: 9.0682e-08\n","Epoch 3/5\n","3125/3125 [==============================] - 200s 64ms/step - loss: 9.8947e-08 - val_loss: 8.7360e-08\n","Epoch 4/5\n","3125/3125 [==============================] - 199s 64ms/step - loss: 9.7617e-08 - val_loss: 9.8071e-08\n","Epoch 5/5\n","3125/3125 [==============================] - 199s 64ms/step - loss: 9.8151e-08 - val_loss: 1.0919e-07\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efe32f627b8>"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"hOxd1-8I-1da","colab_type":"text"},"cell_type":"markdown","source":["Save the model to Google Drive. "]},{"metadata":{"id":"aiwVk7yKpCTF","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save(\"./drive/My Drive/shared/model_b{}_e{}.h5\".format(batch_size, epochs))\n","model.save_weights(\"./drive/My Drive/shared/model_b{}_e{}_weights.h5\".format(batch_size, epochs))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b1RTiSAkbJum","colab_type":"text"},"cell_type":"markdown","source":["Alternatively, we can save the model to the current working environment using:"]},{"metadata":{"id":"5IdpSynObQkI","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save(\"model.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"87LqLncv-8da","colab_type":"text"},"cell_type":"markdown","source":["## Model validation"]},{"metadata":{"id":"qtuduWAhWDem","colab_type":"text"},"cell_type":"markdown","source":["We perform a simple validation with one of the elements of of raw_test."]},{"metadata":{"id":"SmzvYQNbZD_r","colab_type":"code","colab":{}},"cell_type":"code","source":["def recolorize_img(img):\n","  lab = np.asarray(rgb2lab(resize(img, (h,w))/255.))\n","  x_black = lab[:,:,:1]/100.\n","  y_pred = model.predict(x_black.reshape(1,h,w,1))\n","  \n","  res_img = np.empty((h,w,3))\n","  res_img[:,:,:1] = x_black*100\n","  res_img[:,:,1:] = y_pred*128\n","  \n","  rgb = lab2rgb(res_img)*255\n","  \n","  return img_as_ubyte(lab2rgb(res_img)*255)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZS-oRYg2WO3B","colab_type":"code","colab":{}},"cell_type":"code","source":["img = raw_test[13] # Testing on one of the images, for example\n","plt.imshow(img)\n","plt.show()\n","plt.imshow(recolorize_img(img))\n","plt.show()"],"execution_count":0,"outputs":[]}]}